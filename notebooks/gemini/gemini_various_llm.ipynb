{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437ffc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#torch.cuda.empty_cache()\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "#torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df0f57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69b46ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf82a7",
   "metadata": {},
   "source": [
    "## Get the disagreement exist ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e8d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 7)\n",
      "Shape of merged dataframe: (774, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>description_trial1</th>\n",
       "      <th>label_trial1</th>\n",
       "      <th>path_video</th>\n",
       "      <th>analysis_trial1</th>\n",
       "      <th>description_trial3</th>\n",
       "      <th>label_trial3</th>\n",
       "      <th>analysis_trial3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220242</td>\n",
       "      <td>these men stay  sparkles pressed sparkles  che...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A woman in a TikTok video recounts an interact...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/6920327322679692545.mp4</td>\n",
       "      <td>The video criticizes sexism by highlighting an...</td>\n",
       "      <td>The video features a woman recounting and sati...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video depicts sexist ideas attributed to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220296</td>\n",
       "      <td>beaming_face_with_smiling_eyes  ‘school’ pent...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The video contrasts Google image search result...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/6935046770778967302.mp4</td>\n",
       "      <td>The video criticizes sexism by highlighting th...</td>\n",
       "      <td>The video contrasts Google Images search resul...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video itself does not promote or endorse s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220920</td>\n",
       "      <td>don’t laugh at your girlfriends choice, you ar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A woman tells a joke: 'You should never laugh ...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7123342389338443009.mp4</td>\n",
       "      <td>The joke implies that women make poor choices,...</td>\n",
       "      <td>The video features a woman telling a joke advi...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video presents a lighthearted joke about r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220665</td>\n",
       "      <td>women, why do we do this?  woman_facepalming_m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A woman on a bed intentionally shows she's ups...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7039365996053794053.mp4</td>\n",
       "      <td>The video embodies sexism by humorously reinfo...</td>\n",
       "      <td>The video humorously depicts a common relation...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video uses gender stereotypes for comedy b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220746</td>\n",
       "      <td>the struggle is real is caffeinated.  most men...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A woman with purple hair and dark lipstick des...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7067715837255470383.mp4</td>\n",
       "      <td>The video embodies sexism by making a broad ge...</td>\n",
       "      <td>A woman humorously describes the difficulty of...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video makes a lighthearted observation abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_EXIST                                               text  target  \\\n",
       "0    220242  these men stay  sparkles pressed sparkles  che...     1.0   \n",
       "1    220296   beaming_face_with_smiling_eyes  ‘school’ pent...     1.0   \n",
       "2    220920  don’t laugh at your girlfriends choice, you ar...     0.0   \n",
       "3    220665  women, why do we do this?  woman_facepalming_m...     1.0   \n",
       "4    220746  the struggle is real is caffeinated.  most men...     0.0   \n",
       "\n",
       "                                  description_trial1 label_trial1  \\\n",
       "0  A woman in a TikTok video recounts an interact...          YES   \n",
       "1  The video contrasts Google image search result...          YES   \n",
       "2  A woman tells a joke: 'You should never laugh ...          YES   \n",
       "3  A woman on a bed intentionally shows she's ups...          YES   \n",
       "4  A woman with purple hair and dark lipstick des...          YES   \n",
       "\n",
       "                       path_video  \\\n",
       "0  videos/6920327322679692545.mp4   \n",
       "1  videos/6935046770778967302.mp4   \n",
       "2  videos/7123342389338443009.mp4   \n",
       "3  videos/7039365996053794053.mp4   \n",
       "4  videos/7067715837255470383.mp4   \n",
       "\n",
       "                                     analysis_trial1  \\\n",
       "0  The video criticizes sexism by highlighting an...   \n",
       "1  The video criticizes sexism by highlighting th...   \n",
       "2  The joke implies that women make poor choices,...   \n",
       "3  The video embodies sexism by humorously reinfo...   \n",
       "4  The video embodies sexism by making a broad ge...   \n",
       "\n",
       "                                  description_trial3 label_trial3  \\\n",
       "0  The video features a woman recounting and sati...           NO   \n",
       "1  The video contrasts Google Images search resul...           NO   \n",
       "2  The video features a woman telling a joke advi...           NO   \n",
       "3  The video humorously depicts a common relation...           NO   \n",
       "4  A woman humorously describes the difficulty of...           NO   \n",
       "\n",
       "                                     analysis_trial3  \n",
       "0  The video depicts sexist ideas attributed to a...  \n",
       "1  The video itself does not promote or endorse s...  \n",
       "2  The video presents a lighthearted joke about r...  \n",
       "3  The video uses gender stereotypes for comedy b...  \n",
       "4  The video makes a lighthearted observation abo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the subset data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "subset_folder = \"subsets_trial5\"\n",
    "csv_files = [f for f in os.listdir(subset_folder) if f.endswith('.csv')]\n",
    "\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(subset_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"⚠️ UTF-8 failed for {file}, trying ISO-8859-1...\")\n",
    "        df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "df_all = df_all.loc[:, ~df_all.columns.str.startswith('Unnamed:')]\n",
    "df_all = df_all[df_all['description'] != 'ERROR']\n",
    "df_all['id_EXIST'] = df_all['id_EXIST'].astype('Int64')\n",
    "df_all = df_all[df_all['id_EXIST'].notna()]\n",
    "\n",
    "df_trial1 = df_all\n",
    "\n",
    "print(df_trial1.shape)\n",
    "df_trial1.head()\n",
    "\n",
    "subset_folder = \"subsets_trial3\"\n",
    "csv_files = [f for f in os.listdir(subset_folder) if f.endswith('.csv')]\n",
    "\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(subset_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"⚠️ UTF-8 failed for {file}, trying ISO-8859-1...\")\n",
    "        df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "df_all = df_all.loc[:, ~df_all.columns.str.startswith('Unnamed:')]\n",
    "df_all = df_all[df_all['description'] != 'ERROR']\n",
    "df_all['id_EXIST'] = df_all['id_EXIST'].astype('Int64')\n",
    "df_all = df_all[df_all['id_EXIST'].notna()]\n",
    "\n",
    "df_trial3 = df_all\n",
    "df_trial3.head()\n",
    "# Merge the two dataframes on specified columns\n",
    "merged_df = pd.merge(\n",
    "    df_trial1[['id_EXIST', 'text', 'target', 'description','label','path_video','analysis']], \n",
    "    df_trial3[['id_EXIST', 'description','label','analysis']],\n",
    "    on='id_EXIST',\n",
    "    suffixes=('_trial1', '_trial3')\n",
    ")\n",
    "\n",
    "print(\"Shape of merged dataframe:\", merged_df.shape)\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76938fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of disagreement cases: (338, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>description_trial1</th>\n",
       "      <th>label_trial1</th>\n",
       "      <th>path_video</th>\n",
       "      <th>analysis_trial1</th>\n",
       "      <th>description_trial3</th>\n",
       "      <th>label_trial3</th>\n",
       "      <th>analysis_trial3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220242</td>\n",
       "      <td>these men stay  sparkles pressed sparkles  che...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A woman in a TikTok video recounts an interact...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/6920327322679692545.mp4</td>\n",
       "      <td>The video criticizes sexism by highlighting an...</td>\n",
       "      <td>The video features a woman recounting and sati...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video depicts sexist ideas attributed to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220296</td>\n",
       "      <td>beaming_face_with_smiling_eyes  ‘school’ pent...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The video contrasts Google image search result...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/6935046770778967302.mp4</td>\n",
       "      <td>The video criticizes sexism by highlighting th...</td>\n",
       "      <td>The video contrasts Google Images search resul...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video itself does not promote or endorse s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220920</td>\n",
       "      <td>don’t laugh at your girlfriends choice, you ar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A woman tells a joke: 'You should never laugh ...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7123342389338443009.mp4</td>\n",
       "      <td>The joke implies that women make poor choices,...</td>\n",
       "      <td>The video features a woman telling a joke advi...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video presents a lighthearted joke about r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220665</td>\n",
       "      <td>women, why do we do this?  woman_facepalming_m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A woman on a bed intentionally shows she's ups...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7039365996053794053.mp4</td>\n",
       "      <td>The video embodies sexism by humorously reinfo...</td>\n",
       "      <td>The video humorously depicts a common relation...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video uses gender stereotypes for comedy b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220746</td>\n",
       "      <td>the struggle is real is caffeinated.  most men...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A woman with purple hair and dark lipstick des...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7067715837255470383.mp4</td>\n",
       "      <td>The video embodies sexism by making a broad ge...</td>\n",
       "      <td>A woman humorously describes the difficulty of...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video makes a lighthearted observation abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_EXIST                                               text  target  \\\n",
       "0    220242  these men stay  sparkles pressed sparkles  che...     1.0   \n",
       "1    220296   beaming_face_with_smiling_eyes  ‘school’ pent...     1.0   \n",
       "2    220920  don’t laugh at your girlfriends choice, you ar...     0.0   \n",
       "3    220665  women, why do we do this?  woman_facepalming_m...     1.0   \n",
       "4    220746  the struggle is real is caffeinated.  most men...     0.0   \n",
       "\n",
       "                                  description_trial1 label_trial1  \\\n",
       "0  A woman in a TikTok video recounts an interact...          YES   \n",
       "1  The video contrasts Google image search result...          YES   \n",
       "2  A woman tells a joke: 'You should never laugh ...          YES   \n",
       "3  A woman on a bed intentionally shows she's ups...          YES   \n",
       "4  A woman with purple hair and dark lipstick des...          YES   \n",
       "\n",
       "                       path_video  \\\n",
       "0  videos/6920327322679692545.mp4   \n",
       "1  videos/6935046770778967302.mp4   \n",
       "2  videos/7123342389338443009.mp4   \n",
       "3  videos/7039365996053794053.mp4   \n",
       "4  videos/7067715837255470383.mp4   \n",
       "\n",
       "                                     analysis_trial1  \\\n",
       "0  The video criticizes sexism by highlighting an...   \n",
       "1  The video criticizes sexism by highlighting th...   \n",
       "2  The joke implies that women make poor choices,...   \n",
       "3  The video embodies sexism by humorously reinfo...   \n",
       "4  The video embodies sexism by making a broad ge...   \n",
       "\n",
       "                                  description_trial3 label_trial3  \\\n",
       "0  The video features a woman recounting and sati...           NO   \n",
       "1  The video contrasts Google Images search resul...           NO   \n",
       "2  The video features a woman telling a joke advi...           NO   \n",
       "3  The video humorously depicts a common relation...           NO   \n",
       "4  A woman humorously describes the difficulty of...           NO   \n",
       "\n",
       "                                     analysis_trial3  \n",
       "0  The video depicts sexist ideas attributed to a...  \n",
       "1  The video itself does not promote or endorse s...  \n",
       "2  The video presents a lighthearted joke about r...  \n",
       "3  The video uses gender stereotypes for comedy b...  \n",
       "4  The video makes a lighthearted observation abo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for disagreements between trial1 and trial3\n",
    "disagreement_df = merged_df[merged_df['label_trial1'] != merged_df['label_trial3']]\n",
    "print(\"Shape of disagreement cases:\", disagreement_df.shape)\n",
    "disagreement_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae42e63",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22934811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2524, 14)\n",
      "(1000, 14)\n"
     ]
    }
   ],
   "source": [
    "# import libraries pandas matplotlib and seaborn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "data_path = '/Users/moiz.ali/Downloads/EXIST 2025 Dataset V0.3/EXIST 2025 Videos Dataset/training/EXIST2025_training.json'\n",
    "# Normalize the nested JSON into a DataFrame\n",
    "df = pd.read_json(data_path).T\n",
    "\n",
    "print(df.shape)\n",
    "# Display the DataFrame\n",
    "df.head()\n",
    "# Select only the en \n",
    "df = df[df['lang'] == 'en']\n",
    "\n",
    "print(df.shape)\n",
    "# Display the DataFrame\n",
    "df.head()\n",
    "# Creating binary label based on majority vote of labels_task3_1\n",
    "\n",
    "def majority_vote(lst):\n",
    "    return pd.Series(lst).mode().iloc[0]\n",
    "\n",
    "df['target'] = df['labels_task3_1'].apply(majority_vote)\n",
    "df['target'] = df['target'].map({'YES': 1, 'NO': 0})\n",
    "\n",
    "df.head()\n",
    "# Train Test Split\n",
    "# remove the ones with bad videos\n",
    "bad_vids_df = pd.read_csv(\"/Volumes/T7/OMSCS/CLEF2025/EXIST2025/exist-2025/notebooks/bad_videos/bad_videos_log.csv\")\n",
    "bad_vids_df.head()\n",
    "clean_df = df[~df['video'].isin(bad_vids_df['filename'])]\n",
    "clean_df.shape\n",
    "df = clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444325fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>description_trial1</th>\n",
       "      <th>label_trial1</th>\n",
       "      <th>path_video</th>\n",
       "      <th>analysis_trial1</th>\n",
       "      <th>description_trial3</th>\n",
       "      <th>label_trial3</th>\n",
       "      <th>analysis_trial3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220242</td>\n",
       "      <td>these men stay  sparkles pressed sparkles  che...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A woman in a TikTok video recounts an interact...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/6920327322679692545.mp4</td>\n",
       "      <td>The video criticizes sexism by highlighting an...</td>\n",
       "      <td>The video features a woman recounting and sati...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video depicts sexist ideas attributed to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220296</td>\n",
       "      <td>beaming_face_with_smiling_eyes  ‘school’ pent...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The video contrasts Google image search result...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/6935046770778967302.mp4</td>\n",
       "      <td>The video criticizes sexism by highlighting th...</td>\n",
       "      <td>The video contrasts Google Images search resul...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video itself does not promote or endorse s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220920</td>\n",
       "      <td>don’t laugh at your girlfriends choice, you ar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A woman tells a joke: 'You should never laugh ...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7123342389338443009.mp4</td>\n",
       "      <td>The joke implies that women make poor choices,...</td>\n",
       "      <td>The video features a woman telling a joke advi...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video presents a lighthearted joke about r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220665</td>\n",
       "      <td>women, why do we do this?  woman_facepalming_m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A woman on a bed intentionally shows she's ups...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7039365996053794053.mp4</td>\n",
       "      <td>The video embodies sexism by humorously reinfo...</td>\n",
       "      <td>The video humorously depicts a common relation...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video uses gender stereotypes for comedy b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220746</td>\n",
       "      <td>the struggle is real is caffeinated.  most men...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A woman with purple hair and dark lipstick des...</td>\n",
       "      <td>YES</td>\n",
       "      <td>videos/7067715837255470383.mp4</td>\n",
       "      <td>The video embodies sexism by making a broad ge...</td>\n",
       "      <td>A woman humorously describes the difficulty of...</td>\n",
       "      <td>NO</td>\n",
       "      <td>The video makes a lighthearted observation abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_EXIST                                               text  target  \\\n",
       "0    220242  these men stay  sparkles pressed sparkles  che...     1.0   \n",
       "1    220296   beaming_face_with_smiling_eyes  ‘school’ pent...     1.0   \n",
       "2    220920  don’t laugh at your girlfriends choice, you ar...     0.0   \n",
       "3    220665  women, why do we do this?  woman_facepalming_m...     1.0   \n",
       "4    220746  the struggle is real is caffeinated.  most men...     0.0   \n",
       "\n",
       "                                  description_trial1 label_trial1  \\\n",
       "0  A woman in a TikTok video recounts an interact...          YES   \n",
       "1  The video contrasts Google image search result...          YES   \n",
       "2  A woman tells a joke: 'You should never laugh ...          YES   \n",
       "3  A woman on a bed intentionally shows she's ups...          YES   \n",
       "4  A woman with purple hair and dark lipstick des...          YES   \n",
       "\n",
       "                       path_video  \\\n",
       "0  videos/6920327322679692545.mp4   \n",
       "1  videos/6935046770778967302.mp4   \n",
       "2  videos/7123342389338443009.mp4   \n",
       "3  videos/7039365996053794053.mp4   \n",
       "4  videos/7067715837255470383.mp4   \n",
       "\n",
       "                                     analysis_trial1  \\\n",
       "0  The video criticizes sexism by highlighting an...   \n",
       "1  The video criticizes sexism by highlighting th...   \n",
       "2  The joke implies that women make poor choices,...   \n",
       "3  The video embodies sexism by humorously reinfo...   \n",
       "4  The video embodies sexism by making a broad ge...   \n",
       "\n",
       "                                  description_trial3 label_trial3  \\\n",
       "0  The video features a woman recounting and sati...           NO   \n",
       "1  The video contrasts Google Images search resul...           NO   \n",
       "2  The video features a woman telling a joke advi...           NO   \n",
       "3  The video humorously depicts a common relation...           NO   \n",
       "4  A woman humorously describes the difficulty of...           NO   \n",
       "\n",
       "                                     analysis_trial3  \n",
       "0  The video depicts sexist ideas attributed to a...  \n",
       "1  The video itself does not promote or endorse s...  \n",
       "2  The video presents a lighthearted joke about r...  \n",
       "3  The video uses gender stereotypes for comedy b...  \n",
       "4  The video makes a lighthearted observation abo...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4c9735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_Tiktok</th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>video</th>\n",
       "      <th>path_video</th>\n",
       "      <th>url</th>\n",
       "      <th>annotators</th>\n",
       "      <th>number_annotators</th>\n",
       "      <th>gender_annotators</th>\n",
       "      <th>labels_task3_1</th>\n",
       "      <th>labels_task3_2</th>\n",
       "      <th>labels_task3_3</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6605282293726579974</td>\n",
       "      <td>220001</td>\n",
       "      <td>en</td>\n",
       "      <td>6605282293726579974.mp4</td>\n",
       "      <td>videos/6605282293726579974.mp4</td>\n",
       "      <td>https://www.tiktok.com/@sweetheartkittens/vide...</td>\n",
       "      <td>[Annotator_1, Annotator_5]</td>\n",
       "      <td>2</td>\n",
       "      <td>[F, M]</td>\n",
       "      <td>[NO, NO]</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>[[-], [-]]</td>\n",
       "      <td>TRAIN-VIDEO_EN</td>\n",
       "      <td>0</td>\n",
       "      <td>The video features a kitten being petted. Ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6630477888766348549</td>\n",
       "      <td>220002</td>\n",
       "      <td>en</td>\n",
       "      <td>6630477888766348549.mp4</td>\n",
       "      <td>videos/6630477888766348549.mp4</td>\n",
       "      <td>https://www.tiktok.com/@katjaglieson/video/663...</td>\n",
       "      <td>[Annotator_1, Annotator_5, Annotator_10]</td>\n",
       "      <td>3</td>\n",
       "      <td>[F, M, F]</td>\n",
       "      <td>[NO, YES, YES]</td>\n",
       "      <td>[-, DIRECT, JUDGEMENTAL]</td>\n",
       "      <td>[[-], [OBJECTIFICATION], [OBJECTIFICATION]]</td>\n",
       "      <td>TRAIN-VIDEO_EN</td>\n",
       "      <td>1</td>\n",
       "      <td>The video criticizes sexism by portraying catc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6724072000509185286</td>\n",
       "      <td>220004</td>\n",
       "      <td>en</td>\n",
       "      <td>6724072000509185286.mp4</td>\n",
       "      <td>videos/6724072000509185286.mp4</td>\n",
       "      <td>https://www.tiktok.com/@spazzyy00/video/672407...</td>\n",
       "      <td>[Annotator_2, Annotator_6]</td>\n",
       "      <td>2</td>\n",
       "      <td>[F, F]</td>\n",
       "      <td>[NO, NO]</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>[[-], [-]]</td>\n",
       "      <td>TRAIN-VIDEO_EN</td>\n",
       "      <td>0</td>\n",
       "      <td>The video embodies sexism by perpetuating the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6739312750398409990</td>\n",
       "      <td>220005</td>\n",
       "      <td>en</td>\n",
       "      <td>6739312750398409990.mp4</td>\n",
       "      <td>videos/6739312750398409990.mp4</td>\n",
       "      <td>https://www.tiktok.com/@naliuh/video/673931275...</td>\n",
       "      <td>[Annotator_2, Annotator_6, Annotator_10]</td>\n",
       "      <td>3</td>\n",
       "      <td>[F, F, F]</td>\n",
       "      <td>[YES, NO, NO]</td>\n",
       "      <td>[DIRECT, -, -]</td>\n",
       "      <td>[[OBJECTIFICATION], [-], [-]]</td>\n",
       "      <td>TRAIN-VIDEO_EN</td>\n",
       "      <td>0</td>\n",
       "      <td>The video utilizes the \"Hot Mom\" stereotype, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6751959446093647110</td>\n",
       "      <td>220006</td>\n",
       "      <td>en</td>\n",
       "      <td>6751959446093647110.mp4</td>\n",
       "      <td>videos/6751959446093647110.mp4</td>\n",
       "      <td>https://www.tiktok.com/@cringecarter/video/675...</td>\n",
       "      <td>[Annotator_1, Annotator_5]</td>\n",
       "      <td>2</td>\n",
       "      <td>[F, M]</td>\n",
       "      <td>[NO, NO]</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>[[-], [-]]</td>\n",
       "      <td>TRAIN-VIDEO_EN</td>\n",
       "      <td>0</td>\n",
       "      <td>The video's humor stems from the driver's mist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id_Tiktok  id_EXIST lang                    video  \\\n",
       "0  6605282293726579974    220001   en  6605282293726579974.mp4   \n",
       "1  6630477888766348549    220002   en  6630477888766348549.mp4   \n",
       "2  6724072000509185286    220004   en  6724072000509185286.mp4   \n",
       "3  6739312750398409990    220005   en  6739312750398409990.mp4   \n",
       "4  6751959446093647110    220006   en  6751959446093647110.mp4   \n",
       "\n",
       "                       path_video  \\\n",
       "0  videos/6605282293726579974.mp4   \n",
       "1  videos/6630477888766348549.mp4   \n",
       "2  videos/6724072000509185286.mp4   \n",
       "3  videos/6739312750398409990.mp4   \n",
       "4  videos/6751959446093647110.mp4   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.tiktok.com/@sweetheartkittens/vide...   \n",
       "1  https://www.tiktok.com/@katjaglieson/video/663...   \n",
       "2  https://www.tiktok.com/@spazzyy00/video/672407...   \n",
       "3  https://www.tiktok.com/@naliuh/video/673931275...   \n",
       "4  https://www.tiktok.com/@cringecarter/video/675...   \n",
       "\n",
       "                                 annotators number_annotators  \\\n",
       "0                [Annotator_1, Annotator_5]                 2   \n",
       "1  [Annotator_1, Annotator_5, Annotator_10]                 3   \n",
       "2                [Annotator_2, Annotator_6]                 2   \n",
       "3  [Annotator_2, Annotator_6, Annotator_10]                 3   \n",
       "4                [Annotator_1, Annotator_5]                 2   \n",
       "\n",
       "  gender_annotators  labels_task3_1            labels_task3_2  \\\n",
       "0            [F, M]        [NO, NO]                    [-, -]   \n",
       "1         [F, M, F]  [NO, YES, YES]  [-, DIRECT, JUDGEMENTAL]   \n",
       "2            [F, F]        [NO, NO]                    [-, -]   \n",
       "3         [F, F, F]   [YES, NO, NO]            [DIRECT, -, -]   \n",
       "4            [F, M]        [NO, NO]                    [-, -]   \n",
       "\n",
       "                                labels_task3_3           split  target  \\\n",
       "0                                   [[-], [-]]  TRAIN-VIDEO_EN       0   \n",
       "1  [[-], [OBJECTIFICATION], [OBJECTIFICATION]]  TRAIN-VIDEO_EN       1   \n",
       "2                                   [[-], [-]]  TRAIN-VIDEO_EN       0   \n",
       "3                [[OBJECTIFICATION], [-], [-]]  TRAIN-VIDEO_EN       0   \n",
       "4                                   [[-], [-]]  TRAIN-VIDEO_EN       0   \n",
       "\n",
       "                                                text  \n",
       "0  The video features a kitten being petted. Ther...  \n",
       "1  The video criticizes sexism by portraying catc...  \n",
       "2  The video embodies sexism by perpetuating the ...  \n",
       "3  The video utilizes the \"Hot Mom\" stereotype, w...  \n",
       "4  The video's humor stems from the driver's mist...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop text column first, then rename description_trial1 to text\n",
    "\n",
    "# Merge df with merged_df on id_EXIST, keeping only description_trial1 from merged_df\n",
    "# First ensure both dataframes have the same type for id_EXIST\n",
    "df['id_EXIST'] = df['id_EXIST'].astype(int)\n",
    "merged_df['id_EXIST'] = merged_df['id_EXIST'].astype(int)\n",
    "\n",
    "# Then perform the merge\n",
    "merged_df = pd.merge(df, merged_df[['id_EXIST', 'description_trial1','description_trial3','analysis_trial1','analysis_trial3']], on='id_EXIST', how='inner')\n",
    "\n",
    "df = merged_df.copy()\n",
    "# Concatenate the columns with a separator\n",
    "# df['text2'] = df['analysis_trial1'] + df['analysis_trial3'] # Mean Test Accuracy: 0.7302 ± 0.0332\n",
    "df['text2'] = df['analysis_trial1'] + df['analysis_trial3'] + df['description_trial1'] + df['description_trial3']\n",
    "df = df.drop(columns=['text'])\n",
    "df = df.rename(columns={'text2': 'text'})\n",
    "\n",
    "\n",
    "# Drop the individual columns since we've combined them\n",
    "df = df.drop(columns=['description_trial1', 'description_trial3', 'analysis_trial1', 'analysis_trial3'])\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812687c",
   "metadata": {},
   "source": [
    "# Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a345de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, video_ids, exist_ids):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.video_ids = video_ids\n",
    "        self.exist_ids = exist_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['video_ids'] = self.video_ids[idx]\n",
    "        item['exist_ids'] = self.exist_ids[idx]\n",
    "        return item\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "def get_loader(df, batch_size=16, shuffle=False):\n",
    "    texts = df['text'].tolist()\n",
    "    labels = df['target'].tolist()\n",
    "    video_ids = df['video'].tolist()\n",
    "    exist_ids = df['id_EXIST'].tolist()\n",
    "    encodings = tokenize(texts)\n",
    "    dataset = TextDataset(encodings, labels, video_ids, exist_ids)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5c0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(train_loader, val_loader, device, num_labels=2, freeze_layers_up_to=20, epochs=6):\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=num_labels)\n",
    "    \n",
    "    # Freeze embeddings and encoder layers up to `freeze_layers_up_to`\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(\"roberta.embeddings\"):\n",
    "            param.requires_grad = False\n",
    "        elif \"roberta.encoder.layer\" in name:\n",
    "            layer_num = int(name.split(\"layer.\")[1].split(\".\")[0])\n",
    "            if layer_num <= freeze_layers_up_to:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} - Train\"):\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "            outputs = model(**inputs)\n",
    "            loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (torch.argmax(logits, dim=1) == batch['labels']).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} - Val\"):\n",
    "                batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "                inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "                outputs = model(**inputs)\n",
    "                val_loss += outputs.loss.item()\n",
    "                correct += (torch.argmax(outputs.logits, dim=1) == batch['labels']).sum().item()\n",
    "                total += batch['labels'].size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "460d50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold(df, disagreement_df, k=5, device='cuda'):\n",
    "    df['id_EXIST'] = df['id_EXIST'].astype(int)\n",
    "    disagreement_df['id_EXIST'] = disagreement_df['id_EXIST'].astype(int)\n",
    "    \n",
    "    test_df = df[df['id_EXIST'].isin(disagreement_df['id_EXIST'])]\n",
    "    # Keep only 20% of test_df and add remaining 80% to df_train_valid\n",
    "    test_df, remaining_test = train_test_split(test_df, test_size=0.5, random_state=99)\n",
    "    print(\"Shape of test_df after keeping 20%:\", test_df.shape)\n",
    "\n",
    "    # Keep the rest as df_train_valid and add the remaining test samples\n",
    "    df_train_valid = df[~df['id_EXIST'].isin(disagreement_df['id_EXIST'])]\n",
    "    df_train_valid = pd.concat([df_train_valid, remaining_test])\n",
    "    df_train_valid = df_train_valid.reset_index(drop=True)\n",
    "    print(\"Shape of df_train_valid:\", df_train_valid.shape)\n",
    "\n",
    "    # Check that test_df and df_train_valid have no overlapping exist_ids\n",
    "    test_ids = set(test_df['id_EXIST'].unique())\n",
    "    train_valid_ids = set(df_train_valid['id_EXIST'].unique())\n",
    "    assert len(test_ids.intersection(train_valid_ids)) == 0, \"Test set and train/validation set have overlapping IDs\"\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(df_train_valid)):\n",
    "        print(f\"\\n===== Fold {fold_idx+1} =====\")\n",
    "        train_df = df_train_valid.iloc[train_idx]\n",
    "        val_df = df_train_valid.iloc[val_idx]\n",
    "\n",
    "        print(f\"Train set shape: {train_df.shape}\")\n",
    "        print(f\"Validation set shape: {val_df.shape}\")\n",
    "\n",
    "        train_loader = get_loader(train_df, shuffle=True)\n",
    "        val_loader = get_loader(val_df)\n",
    "        model = train_and_validate(train_loader, val_loader, device)\n",
    "\n",
    "        # Optional: Evaluate on the held-out test set\n",
    "        test_loader = get_loader(test_df)\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "                batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "                inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "                outputs = model(**inputs)\n",
    "                preds.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "                targets.extend(batch['labels'].cpu().numpy())\n",
    "        \n",
    "        test_acc = accuracy_score(targets, preds)\n",
    "        print(f\"Fold {fold_idx+1} Test Accuracy: {test_acc:.4f}\")\n",
    "        fold_results.append(test_acc)\n",
    "\n",
    "    print(\"\\n=== K-Fold Summary ===\")\n",
    "    print(f\"Mean Test Accuracy: {np.mean(fold_results):.4f} ± {np.std(fold_results):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98de755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    'deberta-v3': {\n",
    "        'model_name': 'microsoft/deberta-v3-base',\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': AutoModelForSequenceClassification\n",
    "    },\n",
    "    'bertweet': {\n",
    "        'model_name': 'vinai/bertweet-base',\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': AutoModelForSequenceClassification\n",
    "    },\n",
    "    'mdeberta-v3-base': {\n",
    "        'model_name': 'microsoft/mdeberta-v3-base',\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': AutoModelForSequenceClassification\n",
    "    },\n",
    "    'bert-base-uncased': {\n",
    "        'model_name': 'bert-base-uncased',\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': AutoModelForSequenceClassification\n",
    "    },\n",
    "    'beto-uncased': {\n",
    "        'model_name': 'dccuchile/bert-base-spanish-wwm-uncased',\n",
    "        'tokenizer': AutoTokenizer,\n",
    "        'model': AutoModelForSequenceClassification\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ef7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_key, num_labels):\n",
    "    config = MODEL_CONFIGS[model_key]\n",
    "    tokenizer = config['tokenizer'].from_pretrained(config['model_name'])\n",
    "    model = config['model'].from_pretrained(config['model_name'], num_labels=num_labels)\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b03615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 16:03:18,428] A new study created in memory with name: no-name-e88e704a-4f6d-475c-a9ec-b708de108be3\n",
      "/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "[W 2025-05-17 16:03:33,319] Trial 0 failed with parameters: {'learning_rate': 4.20250355772061e-05, 'batch_size': 16, 'epochs': 3, 'weight_decay': 0.057870601529274875} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/b3/39sggkjn14n1xr2hwd01qgpw0000gp/T/ipykernel_20925/1504064466.py\", line 12, in objective\n",
      "    tokenizer, model = load_model_and_tokenizer('deberta-v3', num_labels=2)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/b3/39sggkjn14n1xr2hwd01qgpw0000gp/T/ipykernel_20925/363922235.py\", line 4, in load_model_and_tokenizer\n",
      "    model = config['model'].from_pretrained(config['model_name'], num_labels=num_labels)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 571, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 279, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 4260, in from_pretrained\n",
      "    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 1026, in _get_resolved_checkpoint_files\n",
      "    resolved_archive_file = cached_file(\n",
      "                            ^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/utils/hub.py\", line 266, in cached_file\n",
      "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/utils/hub.py\", line 424, in cached_files\n",
      "    hf_hub_download(\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1008, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1159, in _hf_hub_download_to_cache_dir\n",
      "    _download_to_tmp_and_move(\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 1723, in _download_to_tmp_and_move\n",
      "    http_get(\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/file_download.py\", line 494, in http_get\n",
      "    for chunk in r.iter_content(chunk_size=constants.DOWNLOAD_CHUNK_SIZE):\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/requests/models.py\", line 820, in generate\n",
      "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/urllib3/response.py\", line 1066, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/urllib3/response.py\", line 955, in read\n",
      "    data = self._raw_read(amt)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/urllib3/response.py\", line 879, in _raw_read\n",
      "    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/site-packages/urllib3/response.py\", line 862, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/http/client.py\", line 479, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/socket.py\", line 720, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/ssl.py\", line 1251, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/moiz.ali/miniconda3/envs/exist2025/lib/python3.12/ssl.py\", line 1103, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-17 16:03:33,338] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Create study and optimize\u001b[39;00m\n\u001b[32m     39\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mBest trial:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     43\u001b[39m trial = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m      9\u001b[39m weight_decay = trial.suggest_float(\u001b[33m'\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0.0\u001b[39m, \u001b[32m0.3\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m tokenizer, model = \u001b[43mload_model_and_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdeberta-v3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m model.to(device)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Prepare data loaders\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mload_model_and_tokenizer\u001b[39m\u001b[34m(model_key, num_labels)\u001b[39m\n\u001b[32m      2\u001b[39m config = MODEL_CONFIGS[model_key]\n\u001b[32m      3\u001b[39m tokenizer = config[\u001b[33m'\u001b[39m\u001b[33mtokenizer\u001b[39m\u001b[33m'\u001b[39m].from_pretrained(config[\u001b[33m'\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer, model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/modeling_utils.py:279\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    281\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/modeling_utils.py:4260\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4251\u001b[39m     gguf_file\n\u001b[32m   4252\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4253\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4254\u001b[39m ):\n\u001b[32m   4255\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4256\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4260\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4262\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4267\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4273\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4276\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4278\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4279\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/modeling_utils.py:1026\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1024\u001b[39m         \u001b[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[39;00m\n\u001b[32m   1025\u001b[39m         filename = _add_variant(WEIGHTS_NAME, variant)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m         resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(WEIGHTS_NAME, variant):\n\u001b[32m   1030\u001b[39m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[32m   1031\u001b[39m     resolved_archive_file = cached_file(\n\u001b[32m   1032\u001b[39m         pretrained_model_name_or_path,\n\u001b[32m   1033\u001b[39m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001b[32m   1034\u001b[39m         **cached_file_kwargs,\n\u001b[32m   1035\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/utils/hub.py:266\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    209\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    210\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    211\u001b[39m     **kwargs,\n\u001b[32m    212\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    213\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/transformers/utils/hub.py:424\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    422\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    423\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    439\u001b[39m         snapshot_download(\n\u001b[32m    440\u001b[39m             path_or_repo_id,\n\u001b[32m    441\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    451\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    989\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    990\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1005\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1006\u001b[39m     )\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/file_download.py:1159\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1157\u001b[39m Path(lock_path).parent.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1158\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1159\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1172\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/file_download.py:1723\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1716\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1717\u001b[39m             logger.warning(\n\u001b[32m   1718\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1719\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1720\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1721\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1723\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1728\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1730\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1732\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1733\u001b[39m _chmod_and_move(incomplete_path, destination_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/huggingface_hub/file_download.py:494\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    492\u001b[39m new_resume_size = resume_size\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[32m    496\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/urllib3/response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/urllib3/response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/site-packages/urllib3/response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/exist2025/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])\n",
    "    epochs = trial.suggest_int('epochs', 2, 5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.3)\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    tokenizer, model = load_model_and_tokenizer('deberta-v3', num_labels=2)\n",
    "    model.to(device)\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader = get_loader(train_df, tokenizer, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = get_loader(val_df, tokenizer, batch_size=batch_size)\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            # Training steps\n",
    "            pass  # Implement training steps\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_accuracy = 0\n",
    "        for batch in val_loader:\n",
    "            # Validation steps\n",
    "            pass  # Implement validation steps\n",
    "\n",
    "    return val_accuracy  # Return the validation accuracy for the current trial\n",
    "\n",
    "# Create study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Value: {trial.value}')\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bacd6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_kfold(df, disagreement_df, k=5, device='mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b9c9b",
   "metadata": {},
   "source": [
    "### Keep test as disagreement one ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab3e170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_df after filtering: (338, 15)\n",
      "Shape of test_df after keeping 20%: (169, 15)\n",
      "Shape of df_train_valid: (605, 15)\n",
      "Shape of train_df: (423, 15)\n",
      "Shape of valid_df: (182, 15)\n",
      "\n",
      "Test set sample:\n",
      "\n",
      "Train set sample:\n",
      "\n",
      "Validation set sample:\n",
      "\n",
      "Final shapes:\n",
      "Original df shape: (774, 15)\n",
      "Test df shape: (169, 15)\n",
      "Train df shape: (423, 15)\n",
      "Valid df shape: (182, 15)\n",
      "\n",
      "Proportions:\n",
      "Test set: 21.83%\n",
      "Train set: 54.65%\n",
      "Validation set: 23.51%\n"
     ]
    }
   ],
   "source": [
    "# Convert id_EXIST to same type in both dataframes\n",
    "df['id_EXIST'] = df['id_EXIST'].astype(int)\n",
    "disagreement_df['id_EXIST'] = disagreement_df['id_EXIST'].astype(int)\n",
    "\n",
    "# Filter test_df to only include rows where id_EXIST is in disagreement_df\n",
    "test_df = df[df['id_EXIST'].isin(disagreement_df['id_EXIST'])]\n",
    "print(\"Shape of test_df after filtering:\", test_df.shape)\n",
    "\n",
    "# Keep only 20% of test_df and add remaining 80% to df_train_valid\n",
    "test_df, remaining_test = train_test_split(test_df, test_size=0.5, random_state=1)\n",
    "print(\"Shape of test_df after keeping 20%:\", test_df.shape)\n",
    "\n",
    "# Keep the rest as df_train_valid and add the remaining test samples\n",
    "df_train_valid = df[~df['id_EXIST'].isin(disagreement_df['id_EXIST'])]\n",
    "df_train_valid = pd.concat([df_train_valid, remaining_test])\n",
    "print(\"Shape of df_train_valid:\", df_train_valid.shape)\n",
    "\n",
    "# Split df_train_valid into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(df_train_valid, test_size=0.3, random_state=1)\n",
    "print(\"Shape of train_df:\", train_df.shape)\n",
    "print(\"Shape of valid_df:\", valid_df.shape)\n",
    "\n",
    "# Display first few rows of each split\n",
    "print(\"\\nTest set sample:\")\n",
    "test_df.head()\n",
    "print(\"\\nTrain set sample:\")\n",
    "train_df.head()\n",
    "print(\"\\nValidation set sample:\")\n",
    "valid_df.head()\n",
    "\n",
    "# Print final shapes\n",
    "print(\"\\nFinal shapes:\")\n",
    "print(f\"Original df shape: {df.shape}\")\n",
    "print(f\"Test df shape: {test_df.shape}\")\n",
    "print(f\"Train df shape: {train_df.shape}\")\n",
    "print(f\"Valid df shape: {valid_df.shape}\")\n",
    "\n",
    "# Calculate and print proportions\n",
    "total_samples = len(df)\n",
    "print(\"\\nProportions:\")\n",
    "print(f\"Test set: {len(test_df)/total_samples:.2%}\")\n",
    "print(f\"Train set: {len(train_df)/total_samples:.2%}\")\n",
    "print(f\"Validation set: {len(valid_df)/total_samples:.2%}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194863c5",
   "metadata": {},
   "source": [
    "### Keep disagreement for train, valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "60ea141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split test_df into train, validation and test sets\n",
    "# train_df, temp_df = train_test_split(test_df, test_size=0.3, random_state=42)\n",
    "# valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# print(\"Shape of train_df:\", train_df.shape)\n",
    "# print(\"Shape of valid_df:\", valid_df.shape)\n",
    "# print(\"Shape of test_df:\", test_df.shape)\n",
    "\n",
    "# # Display first few rows of each split\n",
    "# print(\"\\nTrain set sample:\")\n",
    "# train_df.head()\n",
    "# print(\"\\nValidation set sample:\")\n",
    "# valid_df.head()\n",
    "# print(\"\\nTest set sample:\")\n",
    "# test_df.head()\n",
    "\n",
    "# # Print final shapes\n",
    "# print(\"\\nFinal shapes:\")\n",
    "# print(f\"Original test_df shape: {test_df.shape}\")\n",
    "# print(f\"Train df shape: {train_df.shape}\")\n",
    "# print(f\"Valid df shape: {valid_df.shape}\")\n",
    "# print(f\"Test df shape: {test_df.shape}\")\n",
    "\n",
    "# # Calculate and print proportions\n",
    "# total_test_samples = len(test_df)\n",
    "# print(\"\\nProportions:\")\n",
    "# print(f\"Train set: {len(train_df)/total_test_samples:.2%}\")\n",
    "# print(f\"Validation set: {len(valid_df)/total_test_samples:.2%}\")\n",
    "# print(f\"Test set: {len(test_df)/total_test_samples:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "86fa2867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>video</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>220941</td>\n",
       "      <td>7127603784678657285.mp4</td>\n",
       "      <td>The video criticizes sexism by highlighting an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>220969</td>\n",
       "      <td>7136115124112493830.mp4</td>\n",
       "      <td>The video promotes hiding bra straps as the 'c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>220951</td>\n",
       "      <td>7132986111026105646.mp4</td>\n",
       "      <td>The video criticizes sexism by highlighting ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>220943</td>\n",
       "      <td>7128059958972943622.mp4</td>\n",
       "      <td>The video embodies sexism as the man attribute...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>220483</td>\n",
       "      <td>6978573242046958853.mp4</td>\n",
       "      <td>The video's captions, \"When your man has skill...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>220598</td>\n",
       "      <td>7014565389002607877.mp4</td>\n",
       "      <td>The video criticizes sexism by showcasing prot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>220745</td>\n",
       "      <td>7067659840079957294.mp4</td>\n",
       "      <td>The video explicitly criticizes sexism by show...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>220212</td>\n",
       "      <td>6911699116003249409.mp4</td>\n",
       "      <td>The video embodies a scenario rooted in sexism...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>220685</td>\n",
       "      <td>7047184533287963950.mp4</td>\n",
       "      <td>The video criticizes sexist societal prejudice...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>220129</td>\n",
       "      <td>6876237829119249666.mp4</td>\n",
       "      <td>The video criticizes a common sexist argument ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_EXIST                    video  \\\n",
       "726    220941  7127603784678657285.mp4   \n",
       "750    220969  7136115124112493830.mp4   \n",
       "734    220951  7132986111026105646.mp4   \n",
       "727    220943  7128059958972943622.mp4   \n",
       "372    220483  6978573242046958853.mp4   \n",
       "..        ...                      ...   \n",
       "457    220598  7014565389002607877.mp4   \n",
       "574    220745  7067659840079957294.mp4   \n",
       "169    220212  6911699116003249409.mp4   \n",
       "529    220685  7047184533287963950.mp4   \n",
       "98     220129  6876237829119249666.mp4   \n",
       "\n",
       "                                                  text  target  \n",
       "726  The video criticizes sexism by highlighting an...       1  \n",
       "750  The video promotes hiding bra straps as the 'c...       0  \n",
       "734  The video criticizes sexism by highlighting ho...       1  \n",
       "727  The video embodies sexism as the man attribute...       0  \n",
       "372  The video's captions, \"When your man has skill...       0  \n",
       "..                                                 ...     ...  \n",
       "457  The video criticizes sexism by showcasing prot...       1  \n",
       "574  The video explicitly criticizes sexism by show...       1  \n",
       "169  The video embodies a scenario rooted in sexism...       1  \n",
       "529  The video criticizes sexist societal prejudice...       0  \n",
       "98   The video criticizes a common sexist argument ...       1  \n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_path = \"/Volumes/T7/OMSCS/CLEF2025/EXIST2025/exist-2025/notebooks/train_test_split/test_df.csv\"\n",
    "# val_path = \"/Volumes/T7/OMSCS/CLEF2025/EXIST2025/exist-2025/notebooks/train_test_split/valid_df.csv\"\n",
    "# train_path = \"/Volumes/T7/OMSCS/CLEF2025/EXIST2025/exist-2025/notebooks/train_test_split/train_df.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = train_df[['id_EXIST','video','text', 'target']]\n",
    "val_data = valid_df[['id_EXIST','video','text', 'target']]\n",
    "test_data = test_df[['id_EXIST','video','text', 'target']]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b6c691fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_texts = train_data['text'].tolist()\n",
    "train_labels =  train_data['target'].tolist()\n",
    "train_video_ids =  train_data['video'].tolist()\n",
    "train_exist_ids =  train_data['id_EXIST'].tolist()\n",
    "\n",
    "test_texts = test_data['text'].tolist()\n",
    "test_labels =  test_data['target'].tolist()\n",
    "test_video_ids =  test_data['video'].tolist()\n",
    "test_exist_ids =  test_data['id_EXIST'].tolist()\n",
    "\n",
    "val_texts = val_data['text'].tolist()\n",
    "val_labels =  val_data['target'].tolist()\n",
    "val_video_ids =  val_data['video'].tolist()\n",
    "val_exist_ids =  val_data['id_EXIST'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d69f242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "test_encodings = tokenize(test_texts)\n",
    "val_encodings = tokenize(val_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7cb1fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, video_ids, exist_ids):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.video_ids = video_ids\n",
    "        self.exist_ids = exist_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['video_ids'] = self.video_ids[idx]\n",
    "        item['exist_ids'] = self.exist_ids[idx]\n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(train_encodings, train_labels, train_video_ids, train_exist_ids)\n",
    "test_dataset = TextDataset(test_encodings, test_labels, test_video_ids, test_exist_ids)\n",
    "val_dataset = TextDataset(val_encodings, val_labels, val_video_ids, val_exist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3afb7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "72838b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=2)\n",
    "\n",
    "# Freeze embeddings and encoder layers 0–20 (i.e., first 21 layers)\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"roberta.embeddings\"):\n",
    "        param.requires_grad = False\n",
    "    elif \"roberta.encoder.layer\" in name:\n",
    "        layer_num = int(name.split(\"layer.\")[1].split(\".\")[0])\n",
    "        if layer_num < 21:\n",
    "            param.requires_grad = False\n",
    "\n",
    "        \n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                                  lr=2e-05, \n",
    "                                  weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a332fef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 27/27 [01:06<00:00,  2.46s/it, loss=0.697]\n",
      "Epoch 1 - Validation: 100%|██████████| 12/12 [00:19<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.6967, Train Acc: 0.5887 | Val Loss: 0.6596, Val Acc: 0.6209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 27/27 [01:04<00:00,  2.40s/it, loss=0.635]\n",
      "Epoch 2 - Validation: 100%|██████████| 12/12 [00:19<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.6701, Train Acc: 0.5934 | Val Loss: 0.6529, Val Acc: 0.6209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 27/27 [01:05<00:00,  2.42s/it, loss=0.693]\n",
      "Epoch 3 - Validation: 100%|██████████| 12/12 [00:19<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.6575, Train Acc: 0.6383 | Val Loss: 0.6124, Val Acc: 0.6374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 27/27 [01:06<00:00,  2.47s/it, loss=0.404]\n",
      "Epoch 4 - Validation: 100%|██████████| 12/12 [00:20<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.5589, Train Acc: 0.7045 | Val Loss: 0.4204, Val Acc: 0.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training:  52%|█████▏    | 14/27 [00:35<00:31,  2.44s/it, loss=0.446]"
     ]
    }
   ],
   "source": [
    "epochs = 6\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\")\n",
    "    for batch in loop:\n",
    "        batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        \n",
    "        #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "        inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == batch['labels']).sum().item()\n",
    "        total += batch['labels'].size(0)\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} - Validation\"):\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "            inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch['labels']).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "model.eval()\n",
    "test_preds, test_targets = [], []\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Final Test Evaluation\"):\n",
    "        batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "        inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_targets.extend(batch['labels'].cpu().numpy())\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = accuracy_score(test_targets, test_preds)\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0abe77b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Test Evaluation: 100%|██████████| 13/13 [00:22<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.7487\n",
      "Final Test Loss: 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Final Test Evaluation ---\n",
    "model.eval()\n",
    "test_preds, test_targets = [], []\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Final Test Evaluation\"):\n",
    "        batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "        inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_targets.extend(batch['labels'].cpu().numpy())\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = accuracy_score(test_targets, test_preds)\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c4375448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(val_losses, label='Validation Loss', marker='o')\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy', marker='o')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01019e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def generate_predictions(model, dataloader):\n",
    "#     model.eval()\n",
    "#     all_video_ids = []\n",
    "#     all_exist_ids = []\n",
    "#     all_probs = []\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "#     all_constant_column = []  # This will store the constant value \"EXIST2025\"\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Generating Predictions\"):\n",
    "#             batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "#             #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "#             inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "#             outputs = model(**inputs)\n",
    "#             logits = outputs.logits\n",
    "#             probs = F.softmax(logits, dim=1)  # Get probabilities from logits\n",
    "#             preds = torch.argmax(probs, dim=1)  # Get predicted class\n",
    "#             # Map the predictions to \"YES\" (1) or \"NO\" (0)\n",
    "#             preds_mapped = [\"YES\" if pred >=0.5 else \"NO\" for pred in preds.cpu().numpy()]\n",
    "            \n",
    "#             constant_value = \"EXIST2025\"\n",
    "#             constant_column = [constant_value] * len(preds_mapped)\n",
    "            \n",
    "#             all_exist_ids.extend(batch['exist_ids'])\n",
    "#             all_video_ids.extend(batch['video_ids'])\n",
    "#             all_probs.extend(probs.cpu().numpy())\n",
    "#             all_preds.extend(preds_mapped)\n",
    "#             all_labels.extend(batch['labels'].cpu().numpy())\n",
    "#             all_constant_column.extend(constant_column)\n",
    "\n",
    "#     return np.array(all_exist_ids), np.array(all_video_ids), np.array(all_probs), np.array(all_preds), np.array(all_labels), np.array(all_constant_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "976387f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mps\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_predictions(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_video_ids = []\n",
    "    all_exist_ids = []\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_constant_column = []  # This will store the constant value \"EXIST2025\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating Predictions\"):\n",
    "            # Move tensor inputs to device (e.g., mps, cuda, cpu)\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            \n",
    "            # Remove non-model inputs from batch\n",
    "            inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Calculate probabilities and move to CPU before numpy conversion\n",
    "            probs = F.softmax(logits, dim=1).cpu()\n",
    "            \n",
    "            # Get predicted class indices and move to CPU\n",
    "            preds = torch.argmax(probs, dim=1).cpu()\n",
    "            \n",
    "            # Map predictions to \"YES\" or \"NO\" based on predicted class (assuming class 1 = YES)\n",
    "            preds_mapped = [\"YES\" if pred.item() == 1 else \"NO\" for pred in preds]\n",
    "            \n",
    "            # Prepare constant column\n",
    "            constant_value = \"EXIST2025\"\n",
    "            constant_column = [constant_value] * len(preds_mapped)\n",
    "            \n",
    "            # Append results - ensure all tensors are moved to CPU before numpy conversion\n",
    "            # all_exist_ids.extend(batch['exist_ids'])\n",
    "            # all_video_ids.extend(batch['video_ids'])\n",
    "\n",
    "            all_exist_ids.extend(\n",
    "                [x.item() if isinstance(x, torch.Tensor) else x for x in batch['exist_ids']]\n",
    "            )\n",
    "            all_video_ids.extend(\n",
    "                [x.item() if isinstance(x, torch.Tensor) else x for x in batch['video_ids']]\n",
    "            )\n",
    "            all_probs.extend(probs.numpy())  # Already on CPU\n",
    "            all_preds.extend(preds_mapped)\n",
    "            all_labels.extend(batch['labels'].cpu().numpy())\n",
    "            all_constant_column.extend(constant_column)\n",
    "\n",
    "    # Convert lists to numpy arrays, ensuring all tensors are on CPU first\n",
    "    return (\n",
    "        np.array(all_exist_ids),\n",
    "        np.array(all_video_ids),\n",
    "        np.array(all_probs),\n",
    "        np.array(all_preds),\n",
    "        np.array(all_labels),\n",
    "        np.array(all_constant_column)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aefd8827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|██████████| 37/37 [01:04<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.0000\n",
      "Train Macro F1 Score: 0.8805\n",
      "Saved predictions to text_train_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exist_ids, video_ids, probs, preds, labels, titles = generate_predictions(model, train_loader, device=device)\n",
    "\n",
    "test_acc = accuracy_score(labels, preds)\n",
    "\n",
    "preds_binary = [1 if p == \"YES\" else 0 for p in preds]\n",
    "test_f1 = f1_score(labels, preds_binary, average=\"macro\")\n",
    "\n",
    "print(f\"Train Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Train Macro F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"test_case\": titles,\n",
    "    \"id\": exist_ids,\n",
    "    \"value\": preds\n",
    "})\n",
    "\n",
    "df.to_csv(\"text_train_predictions.csv\", index=False)\n",
    "print(\"Saved predictions to text_train_predictions.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a9c18533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|██████████| 13/13 [00:23<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6881\n",
      "Test Macro F1 Score: 0.6859\n",
      "Saved predictions to text_test_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exist_ids, video_ids, probs, preds, labels, titles = generate_predictions(model, test_loader, device=device)\n",
    "\n",
    "preds_binary = [1 if p == \"YES\" else 0 for p in preds]\n",
    "test_acc = accuracy_score(labels, preds_binary)\n",
    "preds_binary = [1 if p == \"YES\" else 0 for p in preds]\n",
    "test_f1 = f1_score(labels, preds_binary, average=\"macro\")\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Macro F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"test_case\": titles,\n",
    "    \"id\": exist_ids,\n",
    "    \"value\": preds\n",
    "})\n",
    "\n",
    "df.to_csv(\"text_test_predictions.csv\", index=False)\n",
    "print(\"Saved predictions to text_test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e71e051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|██████████| 13/13 [00:21<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.0000\n",
      "Val Macro F1 Score: 0.6814\n",
      "Saved predictions to text_val_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exist_ids, video_ids, probs, preds, labels, titles = generate_predictions(model, val_loader,device=device)\n",
    "\n",
    "test_acc = accuracy_score(labels, preds)\n",
    "preds_binary = [1 if p == \"YES\" else 0 for p in preds]\n",
    "test_f1 = f1_score(labels, preds_binary, average=\"macro\")\n",
    "\n",
    "print(f\"Val Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Val Macro F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"test_case\": titles,\n",
    "    \"id\": exist_ids,\n",
    "    \"value\": preds\n",
    "})\n",
    "\n",
    "df.to_csv(\"text_val_predictions.csv\", index=False)\n",
    "print(\"Saved predictions to text_val_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc29c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdcabc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save just the model's state dict (weights)\n",
    "torch.save(model.state_dict(), \"model_weights.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c77b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_3761075/2181143520.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_weights.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate the model architecture first\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=2)\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load(\"model_weights.pt\", map_location=device))\n",
    "\n",
    "# Move to device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6923\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.6308\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.6718\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.6410\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6769\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6718\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.7128\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.7179\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.7026\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6872\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6256\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.7128\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.6513\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.6051\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6103\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5128\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.6308\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.5795\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.6923\n",
      "\n",
      "Training with parameters: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6308\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5744\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.7231\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.5692\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.6974\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6718\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6923\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.6923\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.7436\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.6821\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6667\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6974\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.7077\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.7179\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.5744\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6615\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6667\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.6821\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.7026\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.6000\n",
      "\n",
      "Training with parameters: {'learning_rate': 2e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.5487\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6923\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.5692\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.5692\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.4513\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.0, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.7282\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5692\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.7282\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.7077\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.7231\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 8, 'weight_decay': 0.01, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6462\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6564\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.5692\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.6308\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n",
      "Validation Accuracy: 0.7231\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.0, 'num_frozen_layers': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 20 layers.\n",
      "Validation Accuracy: 0.6718\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5538\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 6 layers.\n",
      "Validation Accuracy: 0.7333\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 12 layers.\n",
      "Validation Accuracy: 0.5692\n",
      "\n",
      "Training with parameters: {'learning_rate': 3e-05, 'batch_size': 16, 'weight_decay': 0.01, 'num_frozen_layers': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Froze first 18 layers.\n"
     ]
    }
   ],
   "source": [
    "#The code below is for search grid which was used to decide the hyperparameters values\n",
    "import itertools\n",
    "\n",
    "# Define your hyperparameter search space\n",
    "param_grid = {\n",
    "    \"learning_rate\": [1e-5, 2e-5, 3e-5, 2e-6],\n",
    "    \"batch_size\": [8, 16],\n",
    "    \"weight_decay\": [0.0, 0.01],\n",
    "    \"num_frozen_layers\": [0, 6, 12, 18, 20]  # NEW!\n",
    "}\n",
    "\n",
    "# Create all combinations\n",
    "param_combinations = list(itertools.product(*param_grid.values()))\n",
    "param_names = list(param_grid.keys())\n",
    "\n",
    "best_val_acc = 0\n",
    "best_params = None\n",
    "\n",
    "for param_values in param_combinations:\n",
    "    params = dict(zip(param_names, param_values))\n",
    "    print(f\"\\nTraining with parameters: {params}\")\n",
    "\n",
    "    # Rebuild model and optimizer each time\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=2)\n",
    "    model.to(device)\n",
    "\n",
    "    # --- Freeze Layers ---\n",
    "    if params[\"num_frozen_layers\"] > 0:\n",
    "        for idx, layer in enumerate(model.roberta.encoder.layer):\n",
    "            if idx < params[\"num_frozen_layers\"]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "        print(f\"✅ Froze first {params['num_frozen_layers']} layers.\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                                  lr=params[\"learning_rate\"], \n",
    "                                  weight_decay=params[\"weight_decay\"])\n",
    "\n",
    "    # Rebuild loaders if batch_size changes\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    # --- Training ---\n",
    "    for epoch in range(2):  # Short training for search\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_params = params\n",
    "\n",
    "print(f\"\\n Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\" Best Parameters: {best_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exist2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
