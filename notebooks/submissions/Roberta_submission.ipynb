{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/Volumes/T7/OMSCS/CLEF2025/EXIST2025/exist-2025/notebooks/train_test_split/test_df.csv\"\n",
    "val_path = \"/Volumes/T7/OMSCS/CLEF2025/EXIST2025/exist-2025/notebooks/train_test_split/valid_df.csv\"\n",
    "train_path = \"/Volumes/T7/OMSCS/CLEF2025/EXIST2025/exist-2025/notebooks/train_test_split/train_df.csv\"\n",
    "\n",
    "# Read the CSV files\n",
    "test_df = pd.read_csv(test_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "# Drop the individual columns since we've combined them\n",
    "# Concatenate description_fp, analysis_fp, and analysis_fn into text column\n",
    "train_df['text'] = train_df['description_fp'] + ' ' + train_df['analysis_fp'] + ' ' + train_df['analysis_fn']\n",
    "val_df['text'] = val_df['description_fp'] + ' ' + val_df['analysis_fp'] + ' ' + val_df['analysis_fn']\n",
    "test_df['text'] = test_df['description_fp'] + ' ' + test_df['analysis_fp'] + ' ' + test_df['analysis_fn']\n",
    "\n",
    "# description_fp+analysis_fp+description_fn (Mean Test Accuracy: 0.8216 ± 0.0177)\n",
    "# df['text'] = df['description_fp'] + ' ' + df['analysis_fp'] + ' ' + df['description_fn']\n",
    "# test_df['text'] = test_df['description_fp'] + ' ' + test_df['analysis_fp'] + ' ' + test_df['description_fn']\n",
    "\n",
    "train_data = train_df[['id_EXIST','video','text', 'target']]\n",
    "val_data = val_df[['id_EXIST','video','text', 'target']]\n",
    "test_data = test_df[['id_EXIST','video','text', 'target']]\n",
    "\n",
    "train_data = train_data.dropna(subset=['text'])\n",
    "val_data = val_data.dropna(subset=['text'])\n",
    "test_data = test_data.dropna(subset=['text'])\n",
    "\n",
    "# train_data['target'] = train_data['target'].map({'YES': 1, 'NO': 0})\n",
    "# val_data['target'] = val_data['target'].map({'YES': 1, 'NO': 0})\n",
    "# test_data['target'] = test_data['target'].map({'YES': 1, 'NO': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>video</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220887</td>\n",
       "      <td>7115146553022631174.mp4</td>\n",
       "      <td>A woman asks a man about his most embarrassing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220250</td>\n",
       "      <td>6922184169908915462.mp4</td>\n",
       "      <td>A woman shares a list of 'Hot Girl Phrases,' w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220514</td>\n",
       "      <td>6984944914136091909.mp4</td>\n",
       "      <td>A young woman answers frequently asked questio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220695</td>\n",
       "      <td>7051661563433995526.mp4</td>\n",
       "      <td>The video uses drawings and narration to illus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220661</td>\n",
       "      <td>7038258256552201477.mp4</td>\n",
       "      <td>The video shows a young woman holding a bass g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>220132</td>\n",
       "      <td>6878835838336240902.mp4</td>\n",
       "      <td>A young woman shares a humorous anecdote about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>220522</td>\n",
       "      <td>6987901203166416134.mp4</td>\n",
       "      <td>A man and a transwoman have a conversation at ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>220544</td>\n",
       "      <td>6993470917552655622.mp4</td>\n",
       "      <td>A man and a woman participate in a \"Men vs wom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>220072</td>\n",
       "      <td>6843454540134501638.mp4</td>\n",
       "      <td>A person films their 'new step bro' in a kitch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>220264</td>\n",
       "      <td>6925645037749554438.mp4</td>\n",
       "      <td>A person filming at night initially mistakes a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_EXIST                    video  \\\n",
       "0      220887  7115146553022631174.mp4   \n",
       "1      220250  6922184169908915462.mp4   \n",
       "2      220514  6984944914136091909.mp4   \n",
       "3      220695  7051661563433995526.mp4   \n",
       "4      220661  7038258256552201477.mp4   \n",
       "..        ...                      ...   \n",
       "189    220132  6878835838336240902.mp4   \n",
       "190    220522  6987901203166416134.mp4   \n",
       "191    220544  6993470917552655622.mp4   \n",
       "192    220072  6843454540134501638.mp4   \n",
       "193    220264  6925645037749554438.mp4   \n",
       "\n",
       "                                                  text  target  \n",
       "0    A woman asks a man about his most embarrassing...       0  \n",
       "1    A woman shares a list of 'Hot Girl Phrases,' w...       1  \n",
       "2    A young woman answers frequently asked questio...       0  \n",
       "3    The video uses drawings and narration to illus...       1  \n",
       "4    The video shows a young woman holding a bass g...       1  \n",
       "..                                                 ...     ...  \n",
       "189  A young woman shares a humorous anecdote about...       0  \n",
       "190  A man and a transwoman have a conversation at ...       0  \n",
       "191  A man and a woman participate in a \"Men vs wom...       1  \n",
       "192  A person films their 'new step bro' in a kitch...       0  \n",
       "193  A person filming at night initially mistakes a...       0  \n",
       "\n",
       "[194 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_texts = train_data['text'].tolist()\n",
    "train_labels =  train_data['target'].tolist()\n",
    "train_video_ids =  train_data['video'].tolist()\n",
    "train_exist_ids =  train_data['id_EXIST'].tolist()\n",
    "\n",
    "test_texts = test_data['text'].tolist()\n",
    "test_labels =  test_data['target'].tolist()\n",
    "test_video_ids =  test_data['video'].tolist()\n",
    "test_exist_ids =  test_data['id_EXIST'].tolist()\n",
    "\n",
    "val_texts = val_data['text'].tolist()\n",
    "val_labels =  val_data['target'].tolist()\n",
    "val_video_ids =  val_data['video'].tolist()\n",
    "val_exist_ids =  val_data['id_EXIST'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "test_encodings = tokenize(test_texts)\n",
    "val_encodings = tokenize(val_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, video_ids, exist_ids):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.video_ids = video_ids\n",
    "        self.exist_ids = exist_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['video_ids'] = self.video_ids[idx]\n",
    "        item['exist_ids'] = self.exist_ids[idx]\n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(train_encodings, train_labels, train_video_ids, train_exist_ids)\n",
    "test_dataset = TextDataset(test_encodings, test_labels, test_video_ids, test_exist_ids)\n",
    "val_dataset = TextDataset(val_encodings, val_labels, val_video_ids, val_exist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-large\", num_labels=2)\n",
    "\n",
    "# Freeze embeddings and encoder layers 0–20 (i.e., first 21 layers)\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"roberta.embeddings\"):\n",
    "        param.requires_grad = False\n",
    "    elif \"roberta.encoder.layer\" in name:\n",
    "        layer_num = int(name.split(\"layer.\")[1].split(\".\")[0])\n",
    "        if layer_num < 21:\n",
    "            param.requires_grad = False\n",
    "\n",
    "        \n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                                  lr=2e-05, \n",
    "                                  weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training: 100%|██████████| 37/37 [04:06<00:00,  6.66s/it, loss=0.732]\n",
      "Epoch 1 - Validation: 100%|██████████| 13/13 [00:29<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.7064, Train Acc: 0.5129 | Val Loss: 0.6263, Val Acc: 0.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training: 100%|██████████| 37/37 [03:57<00:00,  6.43s/it, loss=0.307]\n",
      "Epoch 2 - Validation: 100%|██████████| 13/13 [00:26<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.5852, Train Acc: 0.6867 | Val Loss: 0.5114, Val Acc: 0.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training: 100%|██████████| 37/37 [03:58<00:00,  6.44s/it, loss=0.565]\n",
      "Epoch 3 - Validation: 100%|██████████| 13/13 [00:28<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.5117, Train Acc: 0.7694 | Val Loss: 0.6914, Val Acc: 0.6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training: 100%|██████████| 37/37 [04:03<00:00,  6.57s/it, loss=0.504]\n",
      "Epoch 4 - Validation: 100%|██████████| 13/13 [00:27<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.5285, Train Acc: 0.7246 | Val Loss: 0.4850, Val Acc: 0.7835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training: 100%|██████████| 37/37 [03:57<00:00,  6.43s/it, loss=0.333]\n",
      "Epoch 5 - Validation: 100%|██████████| 13/13 [00:30<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.4631, Train Acc: 0.8072 | Val Loss: 0.4683, Val Acc: 0.7835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training: 100%|██████████| 37/37 [03:53<00:00,  6.31s/it, loss=0.196]\n",
      "Epoch 6 - Validation: 100%|██████████| 13/13 [00:27<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.4304, Train Acc: 0.8072 | Val Loss: 0.4972, Val Acc: 0.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Test Evaluation: 100%|██████████| 13/13 [00:33<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.7938\n",
      "Final Test Loss: 0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 6\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\")\n",
    "    for batch in loop:\n",
    "        batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        \n",
    "        #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "        inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == batch['labels']).sum().item()\n",
    "        total += batch['labels'].size(0)\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} - Validation\"):\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "            inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch['labels']).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "model.eval()\n",
    "test_preds, test_targets = [], []\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Final Test Evaluation\"):\n",
    "        batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "        inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_targets.extend(batch['labels'].cpu().numpy())\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = accuracy_score(test_targets, test_preds)\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Test Evaluation: 100%|██████████| 13/13 [00:06<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.7179\n",
      "Final Test Loss: 0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Final Test Evaluation ---\n",
    "model.eval()\n",
    "test_preds, test_targets = [], []\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Final Test Evaluation\"):\n",
    "        batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        #inputs = {k: v for k, v in batch.items() if k != \"video_ids\"}\n",
    "        inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_targets.extend(batch['labels'].cpu().numpy())\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = accuracy_score(test_targets, test_preds)\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_Tiktok</th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>path_video</th>\n",
       "      <th>url</th>\n",
       "      <th>number_annotators</th>\n",
       "      <th>annotators</th>\n",
       "      <th>gender_annotators</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420001</th>\n",
       "      <td>7246707608772414722</td>\n",
       "      <td>420001</td>\n",
       "      <td>en</td>\n",
       "      <td>before vd. after  face_with_hand_over_mouth  f...</td>\n",
       "      <td>7246707608772414722.mp4</td>\n",
       "      <td>videos/7246707608772414722.mp4</td>\n",
       "      <td>https://www.tiktok.com/@le_zero1/video/7246707...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Annotator_1, Annotator_5]</td>\n",
       "      <td>[F, M]</td>\n",
       "      <td>TEST-VIDEO_EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420002</th>\n",
       "      <td>7242604463045823749</td>\n",
       "      <td>420002</td>\n",
       "      <td>en</td>\n",
       "      <td>♕. editing him with this intro again because w...</td>\n",
       "      <td>7242604463045823749.mp4</td>\n",
       "      <td>videos/7242604463045823749.mp4</td>\n",
       "      <td>https://www.tiktok.com/@gothrx.00/video/724260...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Annotator_2, Annotator_6]</td>\n",
       "      <td>[F, F]</td>\n",
       "      <td>TEST-VIDEO_EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420003</th>\n",
       "      <td>7261068342348303622</td>\n",
       "      <td>420003</td>\n",
       "      <td>en</td>\n",
       "      <td>ni taylor en  lo ilustró mejor listen to your ...</td>\n",
       "      <td>7261068342348303622.mp4</td>\n",
       "      <td>videos/7261068342348303622.mp4</td>\n",
       "      <td>https://www.tiktok.com/@danytorresmiau/video/7...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Annotator_1, Annotator_5]</td>\n",
       "      <td>[F, M]</td>\n",
       "      <td>TEST-VIDEO_EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420004</th>\n",
       "      <td>7095442059926048005</td>\n",
       "      <td>420004</td>\n",
       "      <td>en</td>\n",
       "      <td>clean the previously detected text by removin...</td>\n",
       "      <td>7095442059926048005.mp4</td>\n",
       "      <td>videos/7095442059926048005.mp4</td>\n",
       "      <td>https://www.tiktok.com/@dany.19.19/video/70954...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Annotator_1, Annotator_5]</td>\n",
       "      <td>[F, M]</td>\n",
       "      <td>TEST-VIDEO_EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420005</th>\n",
       "      <td>7231255755746282794</td>\n",
       "      <td>420005</td>\n",
       "      <td>en</td>\n",
       "      <td>my antidepressant my favorite mansplain was wh...</td>\n",
       "      <td>7231255755746282794.mp4</td>\n",
       "      <td>videos/7231255755746282794.mp4</td>\n",
       "      <td>https://www.tiktok.com/@thebrewhounds/video/72...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Annotator_2, Annotator_6]</td>\n",
       "      <td>[F, F]</td>\n",
       "      <td>TEST-VIDEO_EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id_Tiktok id_EXIST lang  \\\n",
       "420001  7246707608772414722   420001   en   \n",
       "420002  7242604463045823749   420002   en   \n",
       "420003  7261068342348303622   420003   en   \n",
       "420004  7095442059926048005   420004   en   \n",
       "420005  7231255755746282794   420005   en   \n",
       "\n",
       "                                                     text  \\\n",
       "420001  before vd. after  face_with_hand_over_mouth  f...   \n",
       "420002  ♕. editing him with this intro again because w...   \n",
       "420003  ni taylor en  lo ilustró mejor listen to your ...   \n",
       "420004   clean the previously detected text by removin...   \n",
       "420005  my antidepressant my favorite mansplain was wh...   \n",
       "\n",
       "                          video                      path_video  \\\n",
       "420001  7246707608772414722.mp4  videos/7246707608772414722.mp4   \n",
       "420002  7242604463045823749.mp4  videos/7242604463045823749.mp4   \n",
       "420003  7261068342348303622.mp4  videos/7261068342348303622.mp4   \n",
       "420004  7095442059926048005.mp4  videos/7095442059926048005.mp4   \n",
       "420005  7231255755746282794.mp4  videos/7231255755746282794.mp4   \n",
       "\n",
       "                                                      url number_annotators  \\\n",
       "420001  https://www.tiktok.com/@le_zero1/video/7246707...                 2   \n",
       "420002  https://www.tiktok.com/@gothrx.00/video/724260...                 2   \n",
       "420003  https://www.tiktok.com/@danytorresmiau/video/7...                 2   \n",
       "420004  https://www.tiktok.com/@dany.19.19/video/70954...                 2   \n",
       "420005  https://www.tiktok.com/@thebrewhounds/video/72...                 2   \n",
       "\n",
       "                        annotators gender_annotators          split  \n",
       "420001  [Annotator_1, Annotator_5]            [F, M]  TEST-VIDEO_EN  \n",
       "420002  [Annotator_2, Annotator_6]            [F, F]  TEST-VIDEO_EN  \n",
       "420003  [Annotator_1, Annotator_5]            [F, M]  TEST-VIDEO_EN  \n",
       "420004  [Annotator_1, Annotator_5]            [F, M]  TEST-VIDEO_EN  \n",
       "420005  [Annotator_2, Annotator_6]            [F, F]  TEST-VIDEO_EN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_test_path = \"/Users/moiz.ali/Downloads/EXIST 2025 Dataset V0.3/EXIST 2025 Videos Dataset/test/EXIST2025_test_clean.json\"\n",
    "df = pd.read_json(clean_test_path).T\n",
    "df = df[df['lang'] == 'en']\n",
    "def majority_vote(lst):\n",
    "    return pd.Series(lst).mode().iloc[0]\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanTextDataset(Dataset):\n",
    "    def __init__(self, encodings, video_ids, exist_ids):\n",
    "        self.encodings = encodings\n",
    "        self.video_ids = video_ids\n",
    "        self.exist_ids = exist_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.exist_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['video_ids'] = self.video_ids[idx]\n",
    "        item['exist_ids'] = self.exist_ids[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_data = df[['id_EXIST','video','text']]\n",
    "clean_test_texts = clean_test_data['text'].tolist()\n",
    "clean_test_video_ids =  clean_test_data['video'].tolist()\n",
    "clean_test_exist_ids =  clean_test_data['id_EXIST'].tolist()\n",
    "clean_test_encodings = tokenize(clean_test_texts)\n",
    "clean_test_dataset = CleanTextDataset(clean_test_encodings, clean_test_video_ids, clean_test_exist_ids)\n",
    "clean_test_loader = DataLoader(clean_test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_predictions_clean_testing(model, dataloader):\n",
    "    model.eval()\n",
    "    all_exist_ids = []\n",
    "    all_video_ids = []\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    all_preds_text =[]\n",
    "    all_titles =[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating Predictions\"):\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)  # Get probabilities from logits\n",
    "            preds = torch.argmax(probs, dim=1)  # Get predicted class\n",
    "            preds_mapped = [\"YES\" if pred >=0.5 else \"NO\" for pred in preds.cpu().numpy()]\n",
    "            constant_value = \"EXIST2025\"\n",
    "            constant_column = [constant_value] * len(preds_mapped)\n",
    "            all_exist_ids.extend(batch['exist_ids'])\n",
    "            all_video_ids.extend(batch['video_ids'])\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_preds_text.extend(preds_mapped)\n",
    "            all_titles.extend(constant_column)\n",
    "\n",
    "    return np.array(all_exist_ids), np.array(all_video_ids), np.array(all_probs), np.array(all_preds), np.array(all_preds_text), np.array(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_predictions_clean_testing_soft(model, dataloader):\n",
    "    model.eval()\n",
    "    all_exist_ids = []\n",
    "    all_video_ids = []\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    all_preds_yes =[]\n",
    "    all_preds_no =[]\n",
    "    all_titles =[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating Predictions\"):\n",
    "            batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "            inputs = {k: v for k, v in batch.items() if k not in [\"video_ids\", \"exist_ids\"]}\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = F.softmax(logits, dim=1)  # Get probabilities from logits\n",
    "            preds = torch.argmax(probs, dim=1)  # Get predicted class\n",
    "            preds_mapped_yes = probs[:,0]\n",
    "            preds_mapped_no = probs[:,1]\n",
    "            constant_value = \"EXIST2025\"\n",
    "            constant_column = [constant_value] * len(preds_mapped_yes)\n",
    "            all_exist_ids.extend(batch['exist_ids'])\n",
    "            all_video_ids.extend(batch['video_ids'])\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_preds_yes.extend(preds_mapped_yes.cpu().numpy())\n",
    "            all_preds_no.extend(preds_mapped_no.cpu().numpy())\n",
    "            all_titles.extend(constant_column)\n",
    "\n",
    "    return np.array(all_exist_ids), np.array(all_video_ids), np.array(all_probs), np.array(all_preds), np.array(all_preds_yes), np.array(all_preds_no), np.array(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|██████████| 24/24 [00:11<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to clean_text_test_predictions_soft.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exist_ids, video_ids, probs, preds, preds_yes, preds_no, titles = generate_predictions_clean_testing_soft(model, clean_test_loader)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"test_case\": titles,\n",
    "    \"id\": exist_ids,\n",
    "    \"value_yes\": preds_yes,\n",
    "    \"value_no\": preds_no\n",
    "})\n",
    "\n",
    "# df.to_csv(\"clean_text_test_predictions_soft.csv\", index=False)\n",
    "# print(\"Saved predictions to clean_text_test_predictions_soft.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to clean_text_test_predictions_soft.json\n"
     ]
    }
   ],
   "source": [
    "df[\"value\"] = df.apply(lambda row: {\"YES\": row[\"value_yes\"], \"NO\": row[\"value_no\"]}, axis=1)\n",
    "df = df.drop(columns=[\"value_yes\", \"value_no\"])\n",
    "\n",
    "df.to_json(\"clean_text_test_predictions_soft.json\", orient=\"records\", indent=2)\n",
    "print(\"Saved predictions to clean_text_test_predictions_soft.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|██████████| 24/24 [00:17<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to clean_text_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "exist_ids, video_ids, probs, preds, preds_text, titles = generate_predictions_clean_testing(model, clean_test_loader)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"test_case\": titles,\n",
    "    \"id\": exist_ids,\n",
    "    \"value\": preds_text\n",
    "})\n",
    "\n",
    "# df.to_csv(\"clean_text_test_predictions.csv\", index=False)\n",
    "# print(\"Saved predictions to clean_text_test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to clean_text_test_predictions.json\n"
     ]
    }
   ],
   "source": [
    "df.to_json(\"clean_text_test_predictions.json\", orient=\"records\", indent=2)\n",
    "print(\"Saved predictions to clean_text_test_predictions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exist2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
